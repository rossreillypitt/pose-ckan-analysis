{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d72a75c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "from dateutil import parser\n",
    "import urllib3\n",
    "import statistics\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bd6f86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datashades_raw_list = \"shades.csv\"\n",
    "\n",
    "outside_list = ['http://data.ctdata.org/',\n",
    "                'https://data.ci.newark.nj.us/',\n",
    "                'https://open.jacksonms.gov/',\n",
    "                'https://data.ca.gov/',\n",
    "                'https://datagate.snap4city.org/'\n",
    "                ]\n",
    "\n",
    "def write_output_file(all_urls_final, filename):\n",
    "    fieldnames = []\n",
    "    for item in all_urls_final:\n",
    "        if len(item.keys()) > len(fieldnames):\n",
    "            fieldnames = item.keys()\n",
    "\n",
    "    with open(filename, \"w\", encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for item in all_urls_final:\n",
    "            writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e483b10c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def datashades_clean_up(datashades_list):\n",
    "    urls = []\n",
    "    with open(datashades_list, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            row_strip = row[0].strip()\n",
    "            if row_strip[:5] == \"href=\":\n",
    "                to_add = row_strip[37:-19]\n",
    "                urls.append(to_add.split('%2F\">')[0])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    clean_urls = []\n",
    "    for item in urls:\n",
    "        item = re.sub(\"%3A\", \":\", item)\n",
    "        item = re.sub(\"%2F\", \"/\", item)\n",
    "        item = re.sub(\"%26\", \"%\", item)\n",
    "        item = re.sub(\"%3D\", \"=\", item)\n",
    "        item = re.sub(\"%3F\", \"?\", item)\n",
    "        item = re.sub(\"%23\", \"#\", item)\n",
    "        clean_urls.append(item)\n",
    "\n",
    "    return clean_urls\n",
    "\n",
    "def dataportals_clean_up():\n",
    "    portals_df = pd.read_csv(\"https://raw.githubusercontent.com/okfn/dataportals.org/master/data/portals.csv\")\n",
    "    portals_list = list(portals_df.url)\n",
    "    return portals_list\n",
    "\n",
    "def url_setup(source, clean_urls):\n",
    "    root_url_set = set()\n",
    "    list_of_url_dicts_2 = []\n",
    "    for item in clean_urls:\n",
    "        root_url = item.split(\"/\")[2]\n",
    "        if root_url in root_url_set:\n",
    "            pass\n",
    "        else:\n",
    "            root_url_set.add(root_url)\n",
    "            url_dict = {}\n",
    "            url_dict[\"source\"] = source\n",
    "            url_dict[\"source_url\"] = item\n",
    "            url_dict[\"root_url\"] = root_url\n",
    "            url_dict[\"base_url\"] = item.split(root_url)[0]+root_url\n",
    "            list_of_url_dicts_2.append(url_dict)\n",
    "    return list_of_url_dicts_2\n",
    "\n",
    "clean_shades_urls = datashades_clean_up(datashades_raw_list)\n",
    "clean_portals_urls = dataportals_clean_up()\n",
    "shades = url_setup(\"datashades.info\", clean_shades_urls)\n",
    "portals = url_setup(\"dataportals.org\", clean_portals_urls)\n",
    "wprdc = url_setup(\"WPRDC\", outside_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2dfb65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def duplicate_removal_processing(list_of_lists_to_deduplicate):\n",
    "    unique_urls = set()\n",
    "    output_list = []\n",
    "    for item in list_of_lists_to_deduplicate:\n",
    "        for items in item:\n",
    "            if items['root_url'] in unique_urls:\n",
    "                pass\n",
    "            else:\n",
    "                output_list.append(items)\n",
    "                unique_urls.add(items['root_url'])\n",
    "    return output_list\n",
    "\n",
    "list_of_lists = [shades, portals, wprdc]\n",
    "combined_and_deduplicated = duplicate_removal_processing(list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf3e82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def checking_for_response(passed_list):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "    full_error_list = []\n",
    "    count = 0\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    for item in passed_list:\n",
    "        count+=1\n",
    "        try:\n",
    "            print(f'Now checking url #{count}: {item[\"source_url\"]}')\n",
    "            response = requests.get(item[\"source_url\"], verify=False, headers=headers, timeout=120)\n",
    "            status = response.status_code\n",
    "            soup = BeautifulSoup(response.text, features=\"html.parser\")\n",
    "            name = str(soup.title.string)\n",
    "            meta_tags = soup.find_all(\"meta\")\n",
    "            if len(meta_tags)>0:\n",
    "                for element in meta_tags:\n",
    "                    if element.get(\"name\") == \"generator\":\n",
    "                        generator = element.get(\"content\")\n",
    "                    else:\n",
    "                        generator = \"\"\n",
    "            else:\n",
    "                generator = \"\"\n",
    "        except AttributeError:\n",
    "            name = \"AttributeError\"\n",
    "        except requests.exceptions.SSLError as ssl_error:\n",
    "            name = \"SSL Error\"\n",
    "            generator = \"\"\n",
    "        except requests.exceptions.ConnectionError as connect_error:\n",
    "            name = \"Connection Error\"\n",
    "            generator = \"\"\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            name = \"Too Many Redirects Error\"\n",
    "            generator = \"\"\n",
    "        except requests.exceptions.Timeout:\n",
    "            name = \"Timeout\"\n",
    "            generator = \"\"\n",
    "        except Exception as e:\n",
    "                try:\n",
    "                    name = e.response.text\n",
    "                except:\n",
    "                    name = \"Error\"\n",
    "        item[\"name\"] = name\n",
    "        item[\"generator\"] = generator\n",
    "        item[\"status_code\"] = status\n",
    "    return passed_list\n",
    "\n",
    "status_response = checking_for_response(combined_and_deduplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c270b749",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datashades.info: {'original_url_list_length': 516, 'count': 516, '200': 478}\n",
      "dataportals.org: {'original_url_list_length': 592, 'count': 510, '200': 419}\n",
      "WPRDC: {'original_url_list_length': 5, 'count': 5, '200': 5}\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {\"datashades.info\": {\"original_url_list_length\": len(shades), \"count\":0, \"200\":0}, \n",
    "              \"dataportals.org\": {\"original_url_list_length\": len(portals), \"count\":0, \"200\":0}, \n",
    "              \"WPRDC\": {\"original_url_list_length\": len(wprdc), \"count\":0, \"200\":0}}\n",
    "\n",
    "for item in status_response:\n",
    "    for items in stats_dict:\n",
    "        if item['source'] == items:\n",
    "            stats_dict[items]['count']+=1\n",
    "            if item['status_code'] == 200:\n",
    "                stats_dict[items]['200']+=1\n",
    "\n",
    "for item in stats_dict:\n",
    "    print(f'{item}: {stats_dict[item]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706839e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def ckan_status_show(passed_list):\n",
    "    full_error_list = []\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "    x=0\n",
    "    for item in passed_list:\n",
    "        x+=1\n",
    "        print(f'Now performing a status_show api call on site #{x}: {item[\"root_url\"]}')\n",
    "        try:\n",
    "            response = requests.get(f'{item[\"source_url\"]}/api/3/action/status_show', verify=False, headers=headers, timeout=120)\n",
    "            content = json.loads(response.content)\n",
    "            item[\"api_base_url\"] = content[\"result\"][\"site_url\"]\n",
    "            item[\"site_title\"] = content[\"result\"][\"site_title\"]\n",
    "            item[\"version\"] = content[\"result\"][\"ckan_version\"]\n",
    "            item[\"locale\"] = content[\"result\"][\"locale_default\"]\n",
    "            item[\"extensions\"] = content[\"result\"][\"extensions\"]\n",
    "            item[\"source_or_base\"] = \"source\"\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                response = requests.get(f'{item[\"base_url\"]}/api/3/action/status_show', verify=False, headers=headers, timeout=120)\n",
    "                content = json.loads(response.content)\n",
    "                item[\"api_base_url\"] = content[\"result\"][\"site_url\"]\n",
    "                item[\"site_title\"] = content[\"result\"][\"site_title\"]\n",
    "                item[\"version\"] = content[\"result\"][\"ckan_version\"]\n",
    "                item[\"locale\"] = content[\"result\"][\"locale_default\"]\n",
    "                item[\"extensions\"] = content[\"result\"][\"extensions\"]\n",
    "                item[\"source_or_base\"] = \"base\"\n",
    "            except Exception as e:\n",
    "                error_list = [item[\"source_url\"], (e.args)]\n",
    "                full_error_list.append(error_list)\n",
    "                pass\n",
    "    return passed_list\n",
    "\n",
    "status_show = ckan_status_show(status_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633a305",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def ckan_all_other_functions(passed_list):\n",
    "    full_error_list_packages = []\n",
    "    full_error_list_orgs = []\n",
    "    full_error_list_tags = []\n",
    "    full_error_list_dates = []\n",
    "    full_error_list_new_dates = []\n",
    "    x=0\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "    api_calls = ['package_list', 'tag_list', 'organization_list']\n",
    "    def api_check(dict_to_check, url_category, api_call):\n",
    "        url = f'{dict_to_check[url_category]}/api/3/action/{api_call}'\n",
    "        response = requests.get(url, verify=False, headers=headers, timeout=120)\n",
    "        content = json.loads(response.content)\n",
    "        dict_to_check[f\"{api_call}_count\"] = len(content[\"result\"])\n",
    "        dict_to_check[f\"{api_call}_source_base_or_apibase\"] = url_category\n",
    "        return dict_to_check\n",
    "\n",
    "    def date_check(dict_to_check, url_category, current_best_metadata_date):\n",
    "        url = f'{dict_to_check[url_category]}/api/3/action/current_package_list_with_resources?limit=2000000'\n",
    "        response = requests.get(url, verify=False, headers=headers, timeout=120)\n",
    "        content = json.loads(response.content)\n",
    "        for items in content[\"result\"]:\n",
    "            metadata_creation_date = items[\"metadata_created\"]\n",
    "            m_c_d = parser.parse(metadata_creation_date)\n",
    "            if m_c_d < current_best_metadata_date:\n",
    "                current_best_metadata_date = m_c_d\n",
    "            else:\n",
    "                pass\n",
    "        item[\"oldest_metadata_created_date\"] = current_best_metadata_date\n",
    "        most_recent_update_date = content[\"result\"][0][\"metadata_modified\"]\n",
    "        item[\"most_recent_update_date\"] = parser.parse(most_recent_update_date)\n",
    "        item[\"dates_source_base_or_apibase\"] = url_category\n",
    "        return dict_to_check\n",
    "\n",
    "    for item in passed_list:\n",
    "        x+=1\n",
    "        print(f'Now performing additional API calls on site #{x}: {item[\"root_url\"]}')\n",
    "        current_best_metadata_date = datetime.now()\n",
    "        for call in api_calls:\n",
    "            try:\n",
    "                api_check(item, \"source_url\", call)\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    api_check(item, \"base_url\", call)\n",
    "                except Exception as e:\n",
    "                    try:\n",
    "                        api_check(item, \"api_base_url\", call)\n",
    "                    except Exception as e:\n",
    "                        error_list = [item[\"source_url\"], (e.args)]\n",
    "                        full_error_list_packages.append(error_list)\n",
    "                        pass\n",
    "        try:\n",
    "            date_check(item, \"source_url\", current_best_metadata_date)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                date_check(item, \"base_url\", current_best_metadata_date)\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    date_check(item, \"api_base_url\", current_best_metadata_date)\n",
    "                except Exception as e:\n",
    "                    error_list = [item[\"source_url\"], (e.args)]\n",
    "                    full_error_list_dates.append(error_list)\n",
    "    return passed_list\n",
    "\n",
    "all_requests_made = ckan_all_other_functions(status_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee86113",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "write_output_file(all_requests_made, \"ckan_requests_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7738670e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def analysis_prep(all_urls_final):\n",
    "    keys_to_pop_1 = ['api_base_url',\n",
    "               'site_title',\n",
    "               'version',\n",
    "               'locale',\n",
    "               'extensions',\n",
    "               'package_list_count',\n",
    "               'organization_list_count',\n",
    "               'tag_list_count',\n",
    "               'oldest_metadata_created_date',\n",
    "               'most_recent_update_date',\n",
    "               ]\n",
    "    keys_to_pop_2 = ['package_list_source_base_or_apibase',\n",
    "                     'tag_list_source_base_or_apibase',\n",
    "                     'organization_list_source_base_or_apibase',\n",
    "                     'dates_source_base_or_apibase']\n",
    "\n",
    "    for item in all_urls_final:\n",
    "        for key in keys_to_pop_1:\n",
    "            if key in item.keys():\n",
    "#                 if pd.isna(item[key]):\n",
    "#                     del item[key]\n",
    "                if item[key] == '':\n",
    "                    del item[key]\n",
    "    for item in all_urls_final:\n",
    "        for keys in keys_to_pop_2:\n",
    "            if keys in item.keys():\n",
    "                del item[keys]\n",
    "\n",
    "#     for item in all_urls_final:\n",
    "#         if 'oldest_metadata_created_date' in item.keys():\n",
    "#             item['oldest_metadata_created_date'] = datetime.strptime(item['oldest_metadata_created_date'][:10], '%Y-%m-%d')\n",
    "#         if 'most_recent_update_date' in item.keys():\n",
    "#             item['most_recent_update_date'] = datetime.strptime(item['most_recent_update_date'][:10], '%Y-%m-%d')\n",
    "    all_urls_final_df = pd.DataFrame(all_urls_final)\n",
    "    all_urls_final_df.to_csv(\"all_urls_final-jul6.csv\")\n",
    "    return all_urls_final\n",
    "\n",
    "prepped = analysis_prep(all_requests_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5991b74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_of_instances_with_packages: 365\n",
      "package_median: 250\n",
      "count_of_datasets_below_1000: 256\n",
      "count_of_datasets_above_50k: 13\n"
     ]
    }
   ],
   "source": [
    "def package_counts(all_urls_final):\n",
    "    count_of_instances_with_packages = 0\n",
    "    packages_counts = []\n",
    "    count_of_datasets_below_1000 = 0\n",
    "    count_of_datasets_above_50k = 0\n",
    "    for item in all_urls_final:\n",
    "        try:\n",
    "            if item['package_list_count']:\n",
    "                count_of_instances_with_packages += 1\n",
    "                packages_counts.append(int(item['package_list_count']))\n",
    "                if int(item['package_list_count']) < 1001:\n",
    "                    count_of_datasets_below_1000 += 1\n",
    "                if int(item['package_list_count']) > 50000:\n",
    "                    count_of_datasets_above_50k += 1\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "        package_median = statistics.median(packages_counts)\n",
    "    export_dict = {\"count_of_instances_with_packages\": count_of_instances_with_packages,\n",
    "                   \"package_median\": package_median,\n",
    "                   \"count_of_datasets_below_1000\": count_of_datasets_below_1000,\n",
    "                   \"count_of_datasets_above_50k\": count_of_datasets_above_50k\n",
    "    }\n",
    "    for item in export_dict:\n",
    "        print(f'{item}: {export_dict[item]}')\n",
    "        \n",
    "package_stats = package_counts(prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbaf060",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def ckan_packages_chart(all_urls_final):\n",
    "    packages = []\n",
    "    for row in all_urls_final:\n",
    "        try:\n",
    "            package_count = row['package_list_count']\n",
    "            if package_count != '':\n",
    "                packages.append(int(package_count))\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    sorted_sizes_adjusted = sorted([1 if s == 0 else s for s in packages], reverse=True)\n",
    "    sizes_plus_ranks = {'rank': range(len(sorted_sizes_adjusted)), 'package_count': sorted_sizes_adjusted}\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    seaborn.histplot(data=sizes_plus_ranks, x='package_count', log_scale=(True, False))\n",
    "    ax.set_xlabel(\"Count of Datasets per Instance\")\n",
    "    ax.set_ylabel(\"Number of Instances\")\n",
    "    plt.xticks(rotation=45)\n",
    "    ax.set_xticklabels(['0', '.1', '1', '10', '100', '1000', '10,000', '100,000', '1,000,000'])\n",
    "    plt.title(\"Fig. 1: Bar Chart of CKAN Instance Size (Measured in Number of Datasets)\\n\", size=8)\n",
    "    plt.savefig(\"packages_chart.png\")\n",
    "    plt.show()\n",
    "\n",
    "ckan_packages_chart(prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab129f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def time_calcs(all_urls_final):\n",
    "    year_list = []\n",
    "    time_dict = {}\n",
    "    today = datetime.today()\n",
    "    url_list = []\n",
    "    overall_count = 0\n",
    "    for y in range(2007, 2024):\n",
    "        annual_count = 0\n",
    "        age = 0\n",
    "        timedeltas = []\n",
    "        age_pct = []\n",
    "        for item in all_urls_final:\n",
    "            try:\n",
    "                if 'oldest_metadata_created_date' in item.keys():\n",
    "                    if 'most_recent_update_date' in item.keys():\n",
    "                        if type(item['oldest_metadata_created_date']) == datetime:\n",
    "                            if type(item['most_recent_update_date']) == datetime:\n",
    "                                year_list.append((item['oldest_metadata_created_date'], item['most_recent_update_date']))\n",
    "                                if int(item['oldest_metadata_created_date'].strftime('%Y')) == y:\n",
    "                                    annual_count+=1\n",
    "                                    overall_count+=1\n",
    "                                    oldest = item['oldest_metadata_created_date']\n",
    "                                    most_recent = item['most_recent_update_date']\n",
    "                                    timedeltas.append(int((most_recent-oldest).days))\n",
    "                                    age_pct.append(int((most_recent-oldest).days) / int((today - oldest).days))\n",
    "                                    url_list.append(item['source_url'])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(item['oldest_metadata_created_date'], item['source_url'], e)\n",
    "        if len(timedeltas)>0:\n",
    "            avg_age = round((sum(timedeltas)/len(timedeltas))/365, 2)\n",
    "            median_age = round(statistics.median(timedeltas)/365, 2)\n",
    "        else:\n",
    "            avg_age = 0\n",
    "            median_age = 0\n",
    "        if len(age_pct)>0:\n",
    "            age_pct_amt = round(((sum(age_pct))/(len(age_pct))), 2)\n",
    "        else:\n",
    "            age_pct_amt = 0\n",
    "        time_dict[y] = {\"year\":y, \"count\": annual_count, \"avg_age\":avg_age, \"median\":median_age, \"average_lifespan\":age_pct_amt}\n",
    "    return(time_dict, overall_count)\n",
    "\n",
    "time_dict, overall_count = time_calcs(prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa8543",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def graphing(time_dict):\n",
    "    time_dict = sorted(time_dict.items())\n",
    "    list_of_time_dicts = [item[1] for item in time_dict]\n",
    "    count_list = []\n",
    "    age_list = []\n",
    "    lifespan_list = []\n",
    "    for item in list_of_time_dicts:\n",
    "        if item[\"count\"] > 0:\n",
    "            count_list.append((item[\"year\"], item[\"count\"]))\n",
    "            age_list.append((item[\"year\"], item[\"avg_age\"]))\n",
    "            lifespan_list.append((item[\"year\"], item[\"average_lifespan\"]))\n",
    "\n",
    "    x_axis_count, y_axis_count = zip(*count_list)\n",
    "    x_axis_age, y_axis_age = zip(*age_list)\n",
    "    x_axis_life, y_axis_life = zip(*lifespan_list)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    bars = ax.bar(x_axis_count, y_axis_count)\n",
    "    ax.set_xlabel(\"Year Launched\", fontsize=12)\n",
    "    ax.set_ylabel(\"Count of Instances\", fontsize=12)\n",
    "    x_list = [2007, 2011, 2013, 2015, 2017, 2019, 2021, 2023]\n",
    "    x = np.array(x_list)\n",
    "    plt.xticks(x, fontsize=12)\n",
    "    ax.bar_label(bars)\n",
    "    ax.set_xlim(2006, 2024)\n",
    "    plt.title(\"Fig. 3: Count of CKAN Instances Launched Per Year, 2007-2023\\n\", size=8)\n",
    "    plt.savefig(\"ckan_per_year.png\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    bars = ax.bar(x_axis_life, y_axis_life, color=\"#1f77b4\")\n",
    "    ax.set_xlabel(\"\\nYear Launched\", fontsize=12)\n",
    "    ax.set_ylabel(\"Average Percent of Lifetime Spent Active\\n\", fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    x_list = [2007, 2011, 2013, 2015, 2017, 2019, 2021, 2023]\n",
    "    x = np.array(x_list)\n",
    "    labels = [str(item) for item in x_axis_life]\n",
    "    plt.xticks(x, fontsize=12)\n",
    "    rects = ax.patches\n",
    "    for rect, label in zip(rects, y_axis_count):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, height + 0.01, label, ha=\"center\", va=\"bottom\")\n",
    "    fig.savefig(\"test.png\", bbox_inches=\"tight\")\n",
    "    plt.title(\"Fig. 4: Average Percent of CKAN Instance 'Lifetime' Spent Active, by Year of Release\\n\", size=8)\n",
    "    plt.savefig(\"ckan_lifetime.png\")\n",
    "    \n",
    "graphing(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cf3ffda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ckan_version(all_urls_final):\n",
    "    version_list = []\n",
    "    for item in all_urls_final:\n",
    "        try:\n",
    "            version_list.append(item['version'].split('.')[:2])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    for item in version_list:\n",
    "        if \"b\" in item[1]:\n",
    "            item[1] = item[1].replace(\"b\", \"\")\n",
    "\n",
    "    version_3_list = [item for item in version_list if item[0] == '3']\n",
    "    for item in version_3_list:\n",
    "        version_list.remove(item)\n",
    "\n",
    "    version_3_list_final = [item for item in version_3_list if item[1] != \"0#datapress\"]\n",
    "    a, b = zip(*version_list)\n",
    "    version_count = Counter(b)\n",
    "    version_dict = {f'2.{item}': version_count[item] for item in version_count}\n",
    "\n",
    "    if len(version_3_list_final) > 0:\n",
    "        c, d = zip(*version_3_list_final)\n",
    "        version_3_count = Counter(d)\n",
    "        version_3_dict = {f'3.{item}': version_3_count[item] for item in version_3_count}\n",
    "        for item in version_3_dict:\n",
    "            version_dict[item] = version_3_dict[item]\n",
    "    x_data = list(sorted(version_dict))\n",
    "    if '2.10' in x_data:\n",
    "        if x_data[-1] == '2.10':\n",
    "            pass\n",
    "        elif x_data[2] == '2.10':\n",
    "            x_data.pop(2)\n",
    "            if x_data[-1] == '2.9':\n",
    "                x_data.append('2.10')\n",
    "            else:\n",
    "                for x in range(len(x_data)):\n",
    "                    if x_data[x][0] == '3':\n",
    "                        insert_point = x\n",
    "                        break\n",
    "                x_data.insert(insert_point, '2.10')\n",
    "    y_data = [version_dict[item] for item in x_data]\n",
    "    return(x_data, y_data)\n",
    "\n",
    "x_data, y_data = ckan_version(prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e32b5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def ckan_version_chart(x_data, y_data):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    bars = ax.bar(x_data, y_data, color=\"#1f77b4\")\n",
    "    ax.set_xlabel(\"\\nCKAN Version\", fontsize=12)\n",
    "    ax.set_ylabel(\"Count of CKAN Instances\\n\", fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    labels = [str(item) for item in x_data]\n",
    "    plt.xticks(labels, fontsize=12)\n",
    "    rects = ax.patches\n",
    "    for rect, label in zip(rects, y_data):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height+ 0.01, label, ha=\"center\", va=\"bottom\")\n",
    "    fig.savefig(\"test.png\", bbox_inches=\"tight\")\n",
    "    plt.title(\"Fig. 5: Count of Analyed CKAN Instances Using CKAN Versions 2.0-2.10\\n\", size=8)\n",
    "    plt.savefig(\"version_count.png\")\n",
    "    plt.show()\n",
    "    \n",
    "ckan_version_chart(x_data, y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}